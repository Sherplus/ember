# import ember
import numpy as np
import os
import datetime
import inspect

# total_data_dir = "/home/mira/research/dataset/ember"
total_data_dir = "D:\\research\\dataset\\ember"
subset = "train_test_3k_3k_1k_1k-v2-third"
subdataset_dir = os.path.join(total_data_dir, "subsets", subset)

subdataset_unit_size = 1000
sub_train_malicious_size = subdataset_unit_size * 3
sub_train_benign_size = subdataset_unit_size * 3
sub_test_malicious_size = subdataset_unit_size
sub_test_benign_size = subdataset_unit_size

# extractor = ember.PEFeatureExtractor()
# dim = extractor.dim
dim = 2351


### write README.txt
with open(os.path.join(subdataset_dir, "README.txt"), "a") as f:
    curtime = str(datetime.datetime.now())
    f.write("[time: {}]\n".format(curtime))
    f.write("find and fix 2 bugs:\n")
    f.write("\n")
    f.write("    sub_test_malicious = X_test[test_benign_rows][:sub_test_malicious_size]\n")
    f.write("\n")
    f.write("amend it into:\n")
    f.write("\n")
    f.write("    sub_test_malicious = X_test[test_malicious_rows][:sub_test_malicious_size]\n")
    f.write("\n")
    
    f.write("and the second one:\n")
    f.write("\n")
    f.write("    for i in range(sub_train_benign_size):\n")
    f.write("        X[i + sub_test_malicious_size] = sub_train_benign[i]\n")
    f.write("        y[i + sub_test_malicious_size] = 0\n")
    f.write("\n")
    f.write("amend it into:\n")
    f.write("\n")
    f.write("    for i in range(sub_train_benign_size):\n")
    f.write("        X[i + sub_train_malicious_size] = sub_train_benign[i]\n")
    f.write("        y[i + sub_train_malicious_size] = 0\n")
    f.write("\n")
    
    f.write("no more changes. that means the dataset get the sample by order, not randomly.\n")
    f.write("so there comes this version of dataset: {}\n".format(subdataset_dir))
    f.write("-- The dataset and this message is generated by script: {} --\n\n\n".format(inspect.getfile(inspect.currentframe())))
    # script filename (usually with path)


def read_full_dataset(total_data_dir):
    print("begin reading full dataset")
    X_train_path = os.path.join(total_data_dir, "X_train.dat")
    y_train_path = os.path.join(total_data_dir, "y_train.dat")
    X_test_path = os.path.join(total_data_dir, "X_test.dat")
    y_test_path = os.path.join(total_data_dir, "y_test.dat")

    X_train = np.memmap(X_train_path, dtype=np.float32, mode="r", shape=(600000, dim))
    y_train = np.memmap(y_train_path, dtype=np.float32, mode="r", shape=600000)
    X_test = np.memmap(X_test_path, dtype=np.float32, mode="r", shape=(200000, dim))
    y_test = np.memmap(y_test_path, dtype=np.float32, mode="r", shape=200000)
    print("done read full dataset")
    return X_train, X_test, y_train, y_test


def segmentation(X_train, X_test, y_train, y_test):
    print("begin segmentation")
    trian_malicious_rows = (y_train == 1)
    trian_benign_rows = (y_train == 0)
    sub_train_malicious = X_train[trian_malicious_rows][:sub_train_malicious_size]
    sub_train_benign = X_train[trian_benign_rows][:sub_train_benign_size]
    del X_train, y_train

    test_malicious_rows = (y_test == 1)
    test_benign_rows = (y_test == 0)
    sub_test_malicious = X_test[test_malicious_rows][:sub_test_malicious_size]
    sub_test_benign = X_test[test_benign_rows][:sub_test_benign_size]
    del X_test, y_test

    print("done segmentation")
    return sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign


def generate_new_dataset(sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign, subdataset_dir):
    print("preparing to merge segmentation as new dataset and write it to disk")

    sub_X_train_path = os.path.join(subdataset_dir, "X_train.dat")
    sub_y_train_path = os.path.join(subdataset_dir, "y_train.dat")
    X = np.memmap(sub_X_train_path, dtype=np.float32, mode="w+", shape=(sub_train_malicious_size + sub_train_benign_size, dim))
    y = np.memmap(sub_y_train_path, dtype=np.float32, mode="w+", shape=(sub_train_malicious_size + sub_train_benign_size))

    for i in range(sub_train_malicious_size):
        X[i] = sub_train_malicious[i]
        y[i] = 1

    for i in range(sub_train_benign_size):
        X[i + sub_train_malicious_size] = sub_train_benign[i]
        y[i + sub_train_malicious_size] = 0
    
    del X, y

    sub_X_test_path = os.path.join(subdataset_dir, "X_test.dat")
    sub_y_test_path = os.path.join(subdataset_dir, "y_test.dat")
    X = np.memmap(sub_X_test_path, dtype=np.float32, mode="w+", shape=(sub_test_benign_size + sub_test_malicious_size, dim))
    y = np.memmap(sub_y_test_path, dtype=np.float32, mode="w+", shape=sub_test_benign_size + sub_test_malicious_size)

    for i in range(sub_test_malicious_size):
        X[i] = sub_test_malicious[i]
        y[i] = 1

    for i in range(sub_test_benign_size):
        X[i + sub_test_malicious_size] = sub_test_benign[i]
        y[i + sub_test_malicious_size] = 0

    print("done generate new dataset and has written it to {}".format(subdataset_dir))
    return


def run():
    print("[time: {}]\n".format(str(datetime.datetime.now())))
    X_train, X_test, y_train, y_test = read_full_dataset(total_data_dir)
    sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign = segmentation(X_train, X_test, y_train, y_test)
    generate_new_dataset(sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign, subdataset_dir)
    print("[time: {}]\n".format(str(datetime.datetime.now())))

if __name__ == "__main__":
    run()
