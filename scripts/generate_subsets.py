# import ember
import numpy as np
import os
import datetime
import inspect

total_data_dir = "/home/mira/research/dataset/ember"
# total_data_dir = "D:\\research\\dataset\\ember"
subset = "train_test_30k_30k_10k_10k"
subdataset_dir = os.path.join(total_data_dir, "subsets", subset)

subdataset_unit_size = 10000
sub_train_malicious_size = subdataset_unit_size * 3
sub_train_benign_size = subdataset_unit_size * 3
sub_test_malicious_size = subdataset_unit_size
sub_test_benign_size = subdataset_unit_size

# extractor = ember.PEFeatureExtractor()
# dim = extractor.dim
dim = 2351


### write README.txt
with open(os.path.join(subdataset_dir, "README.txt"), "a") as f:
    curtime = str(datetime.datetime.now())
    f.write("[time: {}]\n".format(curtime))
        
    f.write("want a larger dataset\n")
    f.write("so there comes this version of dataset: {}\n".format(subdataset_dir))
    f.write("-- The dataset and this message is generated by script: {} --\n\n\n".format(inspect.getfile(inspect.currentframe())))
    # script filename (usually with path)


def read_full_dataset(total_data_dir):
    print("begin reading full dataset")
    X_train_path = os.path.join(total_data_dir, "X_train.dat")
    y_train_path = os.path.join(total_data_dir, "y_train.dat")
    X_test_path = os.path.join(total_data_dir, "X_test.dat")
    y_test_path = os.path.join(total_data_dir, "y_test.dat")

    X_train = np.memmap(X_train_path, dtype=np.float32, mode="r", shape=(900000, dim))
    y_train = np.memmap(y_train_path, dtype=np.float32, mode="r", shape=900000)
    X_test = np.memmap(X_test_path, dtype=np.float32, mode="r", shape=(200000, dim))
    y_test = np.memmap(y_test_path, dtype=np.float32, mode="r", shape=200000)
    print("done read full dataset")
    return X_train, X_test, y_train, y_test


def segmentation(X_train, X_test, y_train, y_test):
    print("begin segmentation")

    # train_malicious_rows = (y_train == 1)
    # train_benign_rows = (y_train == 0)
    # X_train_malicious_rows = X_train[train_malicious_rows]
    # X_train_benign_rows = X_train[train_benign_rows]
    # del X_train, y_train
    # subset_train_malicious_samples = A_Method(X_train_malicious_rows, sub_train_malicious_size)
    # setsub_train_benign_samples = A_Method(X_train_benign_rows, sub_train_benign_size)

    # test_malicious_rows = (y_test == 1)
    # test_benign_rows = (y_test == 0)
    # X_test_malicious_rows = X_test[test_malicious_rows]
    # X_test_benign_rows = X_test[test_benign_rows]
    # del X_test, y_test
    # setsub_test_malicious_samples = A_Method(X_test_malicious_rows, sub_test_malicious_size)
    # setsub_test_benign_samples = A_Method(X_test_benign_rows, sub_test_benign_size)
    
    print("done segmentation")
    # return subset_train_malicious_samples, subset_train_benign_samples, subset_test_malicious_samples, subset_test_benign_samples

def generate_split_data():
    print("begin split data")
    # total_data_dir = total_data_dir
    split_data_dir = '/home/mira/research/dataset/ember/subsets/split_data'

    ### prepare split data object
    train_malicious_samples_path = os.path.join(split_data_dir, "train_malicious_samples.dat")
    train_benign_samples_path = os.path.join(split_data_dir, "train_benign_samples.dat")
    test_malicious_samples_path = os.path.join(split_data_dir, "test_malicious_samples.dat")
    test_benign_samples_path = os.path.join(split_data_dir, "test_benign_samples.dat")

    train_malicious_samples = np.memmap(train_malicious_samples_path, dtype=np.float32, mode="w+", shape=(300000, dim))
    train_benign_samples = np.memmap(train_benign_samples_path, dtype=np.float32, mode="w+", shape=(300000, dim))
    test_malicious_samples = np.memmap(test_malicious_samples_path, dtype=np.float32, mode="w+", shape=(100000, dim))
    test_benign_samples = np.memmap(test_benign_samples_path, dtype=np.float32, mode="w+", shape=(100000, dim))

    X_train, X_test, y_train, y_test = read_full_dataset(total_data_dir)

    train_malicious_rows = (y_train == 1)
    train_benign_rows = (y_train == 0)
    for i, v in enumerate(X_train[train_malicious_rows]):
        train_malicious_samples[i] = v
    for i, v in enumerate(X_train[train_benign_rows]):
        train_benign_samples[i] = v
    del X_train, y_train

    test_malicious_rows = (y_test == 1)
    test_benign_rows = (y_test == 0)
    for i, v in enumerate(X_test[test_malicious_rows]):
        test_malicious_samples[i] = v
    for i, v in enumerate(X_test[test_benign_rows]):
        test_benign_samples[i] = v
    del X_test, y_test

    print("done split data")
    return

def segmentation_from_split_data():
    ### segmentation from splited data
    print("begin segmentation")

    split_data_dir = '/home/mira/research/dataset/ember/subsets/split_data'
    train_malicious_samples_path = os.path.join(split_data_dir, "train_malicious_samples.dat")
    train_benign_samples_path  =   os.path.join(split_data_dir, "train_benign_samples.dat")
    test_malicious_samples_path =  os.path.join(split_data_dir, "test_malicious_samples.dat")
    test_benign_samples_path =     os.path.join(split_data_dir, "test_benign_samples.dat")

    train_malicious_samples = np.memmap(train_malicious_samples_path, dtype=np.float32, mode="r", shape=(300000, dim))
    idx = np.random.choice(300000, size=sub_train_malicious_size, replace=False)
    subset_train_malicious_samples = train_malicious_samples[idx, :]
    del train_malicious_samples

    train_benign_samples = np.memmap(train_benign_samples_path, dtype=np.float32, mode='r', shape=(300000, dim))
    subset_train_benign_samples = train_benign_samples[idx, :]
    del train_benign_samples

    test_malicious_samples = np.memmap(test_malicious_samples_path, dtype=np.float32, mode='r', shape=(100000, dim))
    idx = np.random.choice(100000, size=sub_test_malicious_size, replace=False)
    subset_test_malicious_samples = test_malicious_samples[idx, :]
    del test_malicious_samples

    test_benign_samples = np.memmap(test_benign_samples_path, dtype=np.float32, mode='r', shape=(100000, dim))
    subset_test_benign_samples = test_benign_samples[idx, :]
    del test_benign_samples

    print("done segmentation")
    return subset_train_malicious_samples, subset_train_benign_samples, subset_test_malicious_samples, subset_test_benign_samples


def generate_new_dataset(sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign, subdataset_dir):
    print("preparing to merge segmentation as new dataset and write it to disk")

    sub_X_train_path = os.path.join(subdataset_dir, "X_train.dat")
    sub_y_train_path = os.path.join(subdataset_dir, "y_train.dat")
    X = np.memmap(sub_X_train_path, dtype=np.float32, mode="w+", shape=(sub_train_malicious_size + sub_train_benign_size, dim))
    y = np.memmap(sub_y_train_path, dtype=np.float32, mode="w+", shape=(sub_train_malicious_size + sub_train_benign_size))

    for i in range(sub_train_malicious_size):
        X[i] = sub_train_malicious[i]
        y[i] = 1

    for i in range(sub_train_benign_size):
        X[i + sub_train_malicious_size] = sub_train_benign[i]
        y[i + sub_train_malicious_size] = 0
    
    del X, y

    sub_X_test_path = os.path.join(subdataset_dir, "X_test.dat")
    sub_y_test_path = os.path.join(subdataset_dir, "y_test.dat")
    X = np.memmap(sub_X_test_path, dtype=np.float32, mode="w+", shape=(sub_test_benign_size + sub_test_malicious_size, dim))
    y = np.memmap(sub_y_test_path, dtype=np.float32, mode="w+", shape=sub_test_benign_size + sub_test_malicious_size)

    for i in range(sub_test_malicious_size):
        X[i] = sub_test_malicious[i]
        y[i] = 1

    for i in range(sub_test_benign_size):
        X[i + sub_test_malicious_size] = sub_test_benign[i]
        y[i + sub_test_malicious_size] = 0

    print("done generate new dataset and has written it to {}".format(subdataset_dir))
    return


def run():
    print("[time: {}]\n".format(str(datetime.datetime.now())))

    # X_train, X_test, y_train, y_test = read_full_dataset(total_data_dir)
    # sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign = segmentation(X_train, X_test, y_train, y_test)

    # generate_split_data()
    sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign = segmentation_from_split_data()
    
    generate_new_dataset(sub_train_malicious, sub_train_benign, sub_test_malicious, sub_test_benign, subdataset_dir)
    print("[time: {}]\n".format(str(datetime.datetime.now())))

if __name__ == "__main__":
    run()
